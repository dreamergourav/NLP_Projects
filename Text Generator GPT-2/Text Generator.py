# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11lK5F4QTd-ayFQ_bnNYtUphitizdZS4n
"""

!pip install -q gradio
!pip install -q git+https://github.com/huggingface/transformers.git

import gradio as gr
import tensorflow as tf
from transformers import TFGPT2LMHeadModel, GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = TFGPT2LMHeadModel.from_pretrained("gpt2", pad_token_id=tokenizer.eos_token_id)

# Define a function to generate text using GPT-2
def generate_text(input_text):
    input_ids = tokenizer.encode(input_text, return_tensors="pt")
    output_ids = model.generate(input_ids, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50)
    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    return output_text

input_text = gr.components.Textbox()
output_text = gr.components.Textbox()
iface = gr.Interface(
    fn=generate_text,
    inputs=input_text,
    outputs=output_text,
    title="GPT-2 Text Generation",
    description="OpenAI's GPT-2 is an unsupervised language model that generates coherent text. Input a sentence to see what it completes it with. Takes around 20 seconds to run.",
).launch()

tell